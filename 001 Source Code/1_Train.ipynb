{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Input, Dropout, BatchNormalization, Activation, Add, GlobalAveragePooling2D, Softmax\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.optimizers import Adam, SGD, Adagrad\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.python.client import device_lib\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io as scipy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import h5py\n",
    "import pickle\n",
    "\n",
    "print(device_lib.list_local_devices())\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainset load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_node=4\n",
    "Bound=1\n",
    "N=math.comb(N_node,2)\n",
    "train_data =h5py.File('./trainset.mat','r')\n",
    "X_train = np.array(train_data['distance'])\n",
    "Y_train = np.array(train_data['node_position'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validationset load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_node=4\n",
    "Bound=1\n",
    "N=math.comb(N_node,2)\n",
    "\n",
    "validation_data =h5py.File('./validationset.mat','r')\n",
    "X_validation = np.array(validation_data['distance'])\n",
    "Y_validation = np.array(validation_data['node_position'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ = Input(shape=(X_train.shape[1],))\n",
    "\n",
    "c = Dense(32, input_shape=(X_train.shape[1],)) (input_)\n",
    "c = Activation('ReLU') (c)\n",
    "\n",
    "c = Dense(32) (c)\n",
    "c = Activation('ReLU') (c)\n",
    "\n",
    "output1 = Dense(1, name='output1')(c)\n",
    "output2 = Dense(1, name='output2')(c)\n",
    "output3 = Dense(1, name='output3')(c)\n",
    "output4 = Dense(1, name='output4')(c)\n",
    "output5 = Dense(1, name='output5')(c)\n",
    "output6 = Dense(1, name='output6')(c)\n",
    "output7 = Dense(1, name='output7')(c)\n",
    "\n",
    "model = Model(inputs=[input_],outputs=[output1, output2, output3, output4, output5, output6, output7])\n",
    "\n",
    "model.compile(loss='mse', \n",
    "              optimizer=Adagrad(learning_rate=0.01),\n",
    "              metrics=['mae'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "\n",
    "hist_model = model.fit(X_train, [Y_train[:,0],Y_train[:,1],Y_train[:,2],Y_train[:,3],Y_train[:,4],Y_train[:,5],Y_train[:,6], Y_train[:,8]], batch_size=128, epochs=10, validation_data = (X_validation, \n",
    "                [Y_validation[:,0],Y_validation[:,1],Y_validation[:,2],Y_validation[:,3],Y_validation[:,4],Y_validation[:,5],Y_validation[:,6]], Y_validation[:,7]))\n",
    "\n",
    "\n",
    "model.save('./model.h5') \n",
    "with open('./history.h5', 'wb') as file_pi: pickle.dump(hist_model.history, file_pi)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.subplot(111)           \n",
    "\n",
    "plt.plot(hist_model.history['loss'],'r')\n",
    "plt.plot(hist_model.history['val_loss'],'b--')\n",
    "plt.legend(['Train','Validation'],fontsize = 15)\n",
    "plt.xlabel('epoch',fontsize = 20)\n",
    "plt.ylabel('Loss',fontsize = 20)\n",
    "\n",
    "fig = plt.gcf()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
